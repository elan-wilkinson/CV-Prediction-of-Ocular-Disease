{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# MSAAI-501 Intro to Artificial Intelligence\n",
    "# Group 3 Final Project - Using Computer Vision to Predict Ocular Disease\n",
    "\n",
    "Team Members:\n",
    "  Elan Wilkinson,\n",
    "  Ben Hopwood,\n",
    "  Sarah Durrani\n",
    "\n",
    "\n",
    "### Data Source and Description:\n",
    "\n",
    "Date Source:\n",
    "Maranhão, A. (2020, September 24). Ocular Disease Recognition: Right and left eye fundus photographs of 5000 patients. Kaggle. https://www.kaggle.com/datasets/andrewmvd/ocular-disease-recognition-odir5k  \n",
    "\n",
    "Project Desciption: This project explored taking a fundal image to classify it as appearing healthy or indicative of:\n",
    "  - diabetes\n",
    "  - glaucoma\n",
    "  - cataracts\n",
    "  - age-related macular degeneration\n",
    "  - hypertension\n",
    "  - pathological myopia\n",
    "  - or other diseases/concerns.\n",
    "  \n",
    "This team explored multiple approaches to determine which solution provides the best classification results. These include Convoluted Neural Networks (CNN), Residual Neural Networks (RNN), Support Vector Machines, YOLO, and ResNet. The project estimated the category of disease a fundal image would fall into and give a measure of the agent’s confidence in the classification. While accuracy and precision are paramount metrics to base performance on, the speed/memory required to perform the calculations was also considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Necessary Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>Left-N</th>\n",
       "      <th>Right-N</th>\n",
       "      <th>Left-D</th>\n",
       "      <th>...</th>\n",
       "      <th>Left-C</th>\n",
       "      <th>Right-C</th>\n",
       "      <th>Left-A</th>\n",
       "      <th>Right-A</th>\n",
       "      <th>Left-H</th>\n",
       "      <th>Right-H</th>\n",
       "      <th>Left-M</th>\n",
       "      <th>Right-M</th>\n",
       "      <th>Left-O</th>\n",
       "      <th>Right-O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>branch retinal artery occlusion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "1   1           57        Male  1_left.jpg  1_right.jpg   \n",
       "2   2           42        Male  2_left.jpg  2_right.jpg   \n",
       "3   3           66        Male  3_left.jpg  3_right.jpg   \n",
       "4   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "\n",
       "                            Left-Diagnostic Keywords  \\\n",
       "0                                           cataract   \n",
       "1                                      normal fundus   \n",
       "2  laser spot，moderate non proliferative retinopathy   \n",
       "3                                      normal fundus   \n",
       "4                        macular epiretinal membrane   \n",
       "\n",
       "                Right-Diagnostic Keywords  Left-N  Right-N  Left-D  ...  \\\n",
       "0                           normal fundus       0        1       0  ...   \n",
       "1                           normal fundus       1        1       0  ...   \n",
       "2  moderate non proliferative retinopathy       0        0       1  ...   \n",
       "3         branch retinal artery occlusion       1        0       0  ...   \n",
       "4       mild nonproliferative retinopathy       0        0       0  ...   \n",
       "\n",
       "   Left-C  Right-C  Left-A  Right-A  Left-H  Right-H  Left-M  Right-M  Left-O  \\\n",
       "0       1        0       0        0       0        0       0        0       0   \n",
       "1       0        0       0        0       0        0       0        0       0   \n",
       "2       0        0       0        0       0        0       0        0       0   \n",
       "3       0        0       0        0       0        0       0        0       0   \n",
       "4       0        0       0        0       0        0       0        0       1   \n",
       "\n",
       "   Right-O  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocular_disease_filepath = \"C:/Users/elanw/OneDrive/Documents/IntroToAI/Final_Project/CV-Prediction-of-Ocular-Disease/data_processed.xlsx\"\n",
    "\n",
    "Main_df = pd.read_excel(ocular_disease_filepath)\n",
    "\n",
    "Main_df.drop(['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'], axis=1, inplace=True)\n",
    "\n",
    "Main_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the paths to the dataset folders on my local machine.\n",
    "train_base_dir = 'C:/Users/elanw/OneDrive/Documents/IntroToAI/Final_Project/CV-Prediction-of-Ocular-Disease/ocular-disease-recognition-odir5k/train/'\n",
    "image_dir = 'C:/Users/elanw/OneDrive/Documents/IntroToAI/Final_Project/CV-Prediction-of-Ocular-Disease/ocular-disease-recognition-odir5k/preprocessed_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>Left-N</th>\n",
       "      <th>Right-N</th>\n",
       "      <th>Left-D</th>\n",
       "      <th>...</th>\n",
       "      <th>Left-C</th>\n",
       "      <th>Right-C</th>\n",
       "      <th>Left-A</th>\n",
       "      <th>Right-A</th>\n",
       "      <th>Left-H</th>\n",
       "      <th>Right-H</th>\n",
       "      <th>Left-M</th>\n",
       "      <th>Right-M</th>\n",
       "      <th>Left-O</th>\n",
       "      <th>Right-O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>branch retinal artery occlusion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>5_left.jpg</td>\n",
       "      <td>5_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>6_left.jpg</td>\n",
       "      <td>6_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>moderate non proliferative retinopathy，epireti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>7_left.jpg</td>\n",
       "      <td>7_right.jpg</td>\n",
       "      <td>drusen</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>8_left.jpg</td>\n",
       "      <td>8_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>9_left.jpg</td>\n",
       "      <td>9_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>vitreous degeneration</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "1   1           57        Male  1_left.jpg  1_right.jpg   \n",
       "2   2           42        Male  2_left.jpg  2_right.jpg   \n",
       "3   3           66        Male  3_left.jpg  3_right.jpg   \n",
       "4   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "5   5           50      Female  5_left.jpg  5_right.jpg   \n",
       "6   6           60        Male  6_left.jpg  6_right.jpg   \n",
       "7   7           60      Female  7_left.jpg  7_right.jpg   \n",
       "8   8           59        Male  8_left.jpg  8_right.jpg   \n",
       "9   9           54        Male  9_left.jpg  9_right.jpg   \n",
       "\n",
       "                            Left-Diagnostic Keywords  \\\n",
       "0                                           cataract   \n",
       "1                                      normal fundus   \n",
       "2  laser spot，moderate non proliferative retinopathy   \n",
       "3                                      normal fundus   \n",
       "4                        macular epiretinal membrane   \n",
       "5             moderate non proliferative retinopathy   \n",
       "6                        macular epiretinal membrane   \n",
       "7                                             drusen   \n",
       "8                                      normal fundus   \n",
       "9                                      normal fundus   \n",
       "\n",
       "                           Right-Diagnostic Keywords  Left-N  Right-N  Left-D  \\\n",
       "0                                      normal fundus       0        1       0   \n",
       "1                                      normal fundus       1        1       0   \n",
       "2             moderate non proliferative retinopathy       0        0       1   \n",
       "3                    branch retinal artery occlusion       1        0       0   \n",
       "4                  mild nonproliferative retinopathy       0        0       0   \n",
       "5             moderate non proliferative retinopathy       0        0       1   \n",
       "6  moderate non proliferative retinopathy，epireti...       0        0       0   \n",
       "7                  mild nonproliferative retinopathy       0        0       0   \n",
       "8                                      normal fundus       1        1       0   \n",
       "9                              vitreous degeneration       1        0       0   \n",
       "\n",
       "   ...  Left-C  Right-C  Left-A  Right-A  Left-H  Right-H  Left-M  Right-M  \\\n",
       "0  ...       1        0       0        0       0        0       0        0   \n",
       "1  ...       0        0       0        0       0        0       0        0   \n",
       "2  ...       0        0       0        0       0        0       0        0   \n",
       "3  ...       0        0       0        0       0        0       0        0   \n",
       "4  ...       0        0       0        0       0        0       0        0   \n",
       "5  ...       0        0       0        0       0        0       0        0   \n",
       "6  ...       0        0       0        0       0        0       0        0   \n",
       "7  ...       0        0       0        0       0        0       0        0   \n",
       "8  ...       0        0       0        0       0        0       0        0   \n",
       "9  ...       0        0       0        0       0        0       0        0   \n",
       "\n",
       "   Left-O  Right-O  \n",
       "0       0        0  \n",
       "1       0        0  \n",
       "2       0        0  \n",
       "3       0        1  \n",
       "4       1        0  \n",
       "5       0        0  \n",
       "6       1        0  \n",
       "7       1        0  \n",
       "8       0        0  \n",
       "9       0        1  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "categs = ['C', 'D', 'G', 'O', 'A', 'H', 'M', 'N']\n",
    "\n",
    "if not os.path.exists(train_base_dir):\n",
    "        os.mkdir(train_base_dir)\n",
    "\n",
    "for categ in categs:\n",
    "    if not os.path.exists(train_base_dir + \"\\\\\" + categ):\n",
    "        os.mkdir(train_base_dir + \"\\\\\" + categ)\n",
    "\n",
    "# iterate through main-df for examples that have value of 1 in left-c column_suffixes\n",
    "sides = ['Left','Right']\n",
    "for side in sides:\n",
    "      for cat in categs:\n",
    "        for index,row in Main_df[Main_df[f'{side}-{cat}'] == 1].iterrows():\n",
    "                file = row[f'{side}-Fundus']\n",
    "                if os.path.isfile(image_dir + file):\n",
    "                        shutil.copy(image_dir + file, train_base_dir + \"/\" + cat + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once, to iterate through the examples in the csv, and reorganize the images into subfolders by label\n",
    "\n",
    "ocular_data = pd.read_csv(\"C:\\\\Users\\\\elanw\\\\OneDrive\\\\Documents\\\\IntroToAI\\\\ocular_dataset\\\\full_df.csv\")\n",
    "\n",
    "categs = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "\n",
    "if not os.path.exists(train_base_dir):\n",
    "        os.mkdir(train_base_dir)\n",
    "\n",
    "for categ in categs:\n",
    "    if not os.path.exists(train_base_dir + \"\\\\\" + categ):\n",
    "        os.mkdir(train_base_dir + \"\\\\\" + categ)\n",
    "\n",
    "#Normal (N),\n",
    "#Diabetes (D),\n",
    "#Glaucoma (G),\n",
    "#Cataract (C),\n",
    "#Age related Macular Degeneration (A),\n",
    "#Hypertension (H),\n",
    "#Pathological Myopia (M),\n",
    "#Other diseases/abnormalities (O)\n",
    "\n",
    "\n",
    "\n",
    "for index, row in ocular_data.iterrows():\n",
    "    l_file = str(row['ID']) + \"_left.jpg\"\n",
    "    r_file = str(row['ID'])+ \"_right.jpg\"\n",
    "    if row['N'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\N\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\N\\\\\"\n",
    "    elif row['D'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\D\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\D\\\\\"\n",
    "    elif row['G'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\G\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\G\\\\\"\n",
    "    elif row['C'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\C\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\C\\\\\"\n",
    "    elif row['A'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\A\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\A\\\\\"\n",
    "    elif row['H'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\H\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\H\\\\\"\n",
    "    elif row['M'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\M\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\M\\\\\"\n",
    "    elif row['O'] == 1:\n",
    "        ldest = train_base_dir + \"\\\\O\\\\\"\n",
    "        rdest = train_base_dir + \"\\\\O\\\\\"\n",
    "    if \"normal\" in row['Left-Diagnostic Keywords'].lower():\n",
    "        ldest = train_base_dir + \"\\\\N\\\\\"\n",
    "    elif \"cataract\" in row['Left-Diagnostic Keywords'].lower():\n",
    "        ldest = train_base_dir + \"\\\\C\\\\\"\n",
    "    elif \"pathological myopia\" in row['Left-Diagnostic Keywords'].lower():\n",
    "        ldest = train_base_dir + \"\\\\C\\\\\"\n",
    "    if \"normal\" in row['Right-Diagnostic Keywords'].lower():\n",
    "        rdest = train_base_dir + \"\\\\N\\\\\"\n",
    "    elif \"cataract\" in row['Right-Diagnostic Keywords'].lower():\n",
    "        rdest = train_base_dir + \"\\\\C\\\\\"\n",
    "    elif \"pathological myopia\" in row['Right-Diagnostic Keywords'].lower():\n",
    "        rdest = train_base_dir + \"\\\\C\\\\\"    \n",
    "    if os.path.exists(image_dir + l_file):\n",
    "        shutil.copy(image_dir + l_file, ldest + l_file)\n",
    "    if os.path.exists(image_dir + r_file):\n",
    "        shutil.copy(image_dir + r_file, rdest + r_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This duplicates training data by creating a horizontally flipped version of each.\n",
    "\n",
    "categs = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "for category in categs:\n",
    "    for file in os.listdir(train_base_dir + \"\\\\\" + category):\n",
    "        img = cv2.imread(train_base_dir + \"\\\\\" + category + \"\\\\\" + file)\n",
    "        flipped_img = cv2.flip(img, 1)\n",
    "        cv2.imwrite(train_base_dir + \"\\\\\" + category + \"\\\\\" + file[:-4] + \"_flipped.jpg\", flipped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes right images and flips them horizontally \n",
    "\n",
    "categs = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "for category in categs:\n",
    "    for file in os.listdir(train_base_dir + \"\\\\\" + category):\n",
    "        if file.__contains__(\"right\"):\n",
    "            img = cv2.imread(train_base_dir + \"\\\\\" + category + \"\\\\\" + file)\n",
    "            flipped_img = cv2.flip(img, 1)\n",
    "            cv2.imwrite(train_base_dir + \"\\\\\" + category + \"\\\\\" + file[:-4] + \".jpg\", flipped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base model for VGG16, using frozen pretrained weights from imagenet\n",
    "# reducing the image size to 224x224\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "base_model = VGG16(weights='imagenet',\n",
    "                   input_shape=(224, 224, 3),\n",
    "                   include_top=False)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2 dense layers and a prediction layer to the base model\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer = layers.Dense(80, activation='relu')\n",
    "dense_layer2 = layers.Dense(40, activation='relu')\n",
    "prediction_layer = layers.Dense(8, activation='softmax')\n",
    "\n",
    "xfer_vgg16_model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer,\n",
    "    dense_layer2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model, using sparse categorical crossentropy rather than categorial\n",
    "# because we have category labels that are exclusive from one another\n",
    "# and data cannot be in more than one category\n",
    "# Using Adam as the optimizer as experimentations running the model with SGD with various learning rates\n",
    "# had inferior performance\n",
    "xfer_vgg16_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Image Data Generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=False, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5373 images belonging to 8 classes.\n",
      "Found 1338 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow images from directories with label data\n",
    "# Setting class mode to sparse categorical for sparse categorical crossentropy\n",
    "# Batch size 20-32 seems to perform well\n",
    "# Shuffle set to false for validation data, as .labels and .classes returns labels in order, not matching shuffle status\n",
    "# Keeping color mode rgb - vgg16 requires 3 input channels, and when using PIL and manually converting to grayscale,\n",
    "# the model performance was not improved\n",
    "train_it = train_datagen.flow_from_directory(train_base_dir, target_size=(224, 224), color_mode='rgb', class_mode='sparse', batch_size=32,  subset='training',  shuffle=True)\n",
    "valid_it = train_datagen.flow_from_directory(train_base_dir, target_size=(224, 224), color_mode='rgb', class_mode='sparse', batch_size=32,  subset='validation', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "168/168 [==============================] - 470s 3s/step - loss: 3.7870 - accuracy: 0.4212 - val_loss: 3.0095 - val_accuracy: 0.3976\n",
      "Epoch 2/20\n",
      "168/168 [==============================] - 459s 3s/step - loss: 1.7740 - accuracy: 0.5351 - val_loss: 2.8695 - val_accuracy: 0.3535\n",
      "Epoch 3/20\n",
      "168/168 [==============================] - 441s 3s/step - loss: 1.1756 - accuracy: 0.6036 - val_loss: 2.1896 - val_accuracy: 0.4761\n",
      "Epoch 4/20\n",
      "168/168 [==============================] - 441s 3s/step - loss: 0.9435 - accuracy: 0.6594 - val_loss: 2.1280 - val_accuracy: 0.4148\n",
      "Epoch 5/20\n",
      "168/168 [==============================] - 441s 3s/step - loss: 0.9029 - accuracy: 0.6691 - val_loss: 2.0296 - val_accuracy: 0.4626\n",
      "Epoch 6/20\n",
      "168/168 [==============================] - 441s 3s/step - loss: 0.7923 - accuracy: 0.7173 - val_loss: 2.3014 - val_accuracy: 0.4200\n",
      "Epoch 7/20\n",
      "168/168 [==============================] - 439s 3s/step - loss: 0.7537 - accuracy: 0.7238 - val_loss: 2.1849 - val_accuracy: 0.5067\n",
      "Epoch 8/20\n",
      "168/168 [==============================] - 440s 3s/step - loss: 0.6425 - accuracy: 0.7685 - val_loss: 2.2941 - val_accuracy: 0.4619\n",
      "Epoch 9/20\n",
      "168/168 [==============================] - 437s 3s/step - loss: 0.6244 - accuracy: 0.7763 - val_loss: 2.3098 - val_accuracy: 0.4499\n",
      "Epoch 10/20\n",
      "168/168 [==============================] - 436s 3s/step - loss: 0.6409 - accuracy: 0.7664 - val_loss: 2.3594 - val_accuracy: 0.4611\n",
      "Epoch 11/20\n",
      "168/168 [==============================] - 438s 3s/step - loss: 0.5317 - accuracy: 0.8079 - val_loss: 2.3956 - val_accuracy: 0.5030\n",
      "Epoch 12/20\n",
      "168/168 [==============================] - 436s 3s/step - loss: 0.5220 - accuracy: 0.8094 - val_loss: 2.4963 - val_accuracy: 0.4671\n",
      "Epoch 13/20\n",
      "168/168 [==============================] - 434s 3s/step - loss: 0.4803 - accuracy: 0.8236 - val_loss: 3.2192 - val_accuracy: 0.4185\n",
      "Epoch 14/20\n",
      "168/168 [==============================] - 434s 3s/step - loss: 0.4687 - accuracy: 0.8230 - val_loss: 2.6514 - val_accuracy: 0.4694\n",
      "Epoch 15/20\n",
      "168/168 [==============================] - 431s 3s/step - loss: 0.4764 - accuracy: 0.8267 - val_loss: 2.7333 - val_accuracy: 0.4126\n",
      "Epoch 16/20\n",
      "168/168 [==============================] - 432s 3s/step - loss: 0.4369 - accuracy: 0.8431 - val_loss: 3.0955 - val_accuracy: 0.4432\n",
      "Epoch 17/20\n",
      "168/168 [==============================] - 432s 3s/step - loss: 0.4777 - accuracy: 0.8223 - val_loss: 3.3460 - val_accuracy: 0.4148\n",
      "Epoch 18/20\n",
      "168/168 [==============================] - 433s 3s/step - loss: 0.4042 - accuracy: 0.8524 - val_loss: 3.1122 - val_accuracy: 0.4342\n",
      "Epoch 19/20\n",
      "168/168 [==============================] - 434s 3s/step - loss: 0.4154 - accuracy: 0.8507 - val_loss: 3.1612 - val_accuracy: 0.4387\n",
      "Epoch 20/20\n",
      "168/168 [==============================] - 432s 3s/step - loss: 0.4046 - accuracy: 0.8515 - val_loss: 3.2961 - val_accuracy: 0.4880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22767b3f610>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model for 20 epochs\n",
    "xfer_vgg16_model.fit(train_it, epochs=20, validation_data=valid_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the model continuing to overfit to the training data, while validation accuracy hovers around 40% without improving. These results seem to be consistent regardless of color or greyscale or whether using the SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 89s 2s/step\n",
      "0.476831091180867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = xfer_vgg16_model.predict(valid_it)\n",
    "score = accuracy_score(y_true=valid_it.classes, y_pred=predictions.argmax(axis=-1))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        55\n",
      "           1       0.64      0.57      0.60        60\n",
      "           2       0.42      0.46      0.44       371\n",
      "           3       0.22      0.27      0.24        62\n",
      "           4       0.00      0.00      0.00        38\n",
      "           5       0.59      0.32      0.42        50\n",
      "           6       0.58      0.67      0.62       575\n",
      "           7       0.21      0.13      0.16       127\n",
      "\n",
      "    accuracy                           0.48      1338\n",
      "   macro avg       0.33      0.30      0.31      1338\n",
      "weighted avg       0.45      0.48      0.46      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(valid_it.classes, predictions.argmax(axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that while the weakest performance is on the class with the fewest examples (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "168/168 [==============================] - 438s 3s/step - loss: 2.4516 - accuracy: 0.4085 - val_loss: 1.8732 - val_accuracy: 0.4402\n",
      "Epoch 2/20\n",
      "168/168 [==============================] - 438s 3s/step - loss: 1.3854 - accuracy: 0.5079 - val_loss: 1.7300 - val_accuracy: 0.4268\n",
      "Epoch 3/20\n",
      "168/168 [==============================] - 440s 3s/step - loss: 1.2070 - accuracy: 0.5563 - val_loss: 1.6780 - val_accuracy: 0.4880\n",
      "Epoch 4/20\n",
      "168/168 [==============================] - 444s 3s/step - loss: 1.0730 - accuracy: 0.6054 - val_loss: 1.9118 - val_accuracy: 0.4268\n",
      "Epoch 5/20\n",
      "168/168 [==============================] - 443s 3s/step - loss: 1.0081 - accuracy: 0.6222 - val_loss: 1.7847 - val_accuracy: 0.4410\n",
      "Epoch 6/20\n",
      "168/168 [==============================] - 443s 3s/step - loss: 0.9473 - accuracy: 0.6449 - val_loss: 1.8186 - val_accuracy: 0.4581\n",
      "Epoch 7/20\n",
      "168/168 [==============================] - 442s 3s/step - loss: 0.8915 - accuracy: 0.6592 - val_loss: 1.7480 - val_accuracy: 0.4357\n",
      "Epoch 8/20\n",
      "168/168 [==============================] - 490s 3s/step - loss: 0.8180 - accuracy: 0.6899 - val_loss: 1.9640 - val_accuracy: 0.4604\n",
      "Epoch 9/20\n",
      "168/168 [==============================] - 516s 3s/step - loss: 0.7852 - accuracy: 0.6910 - val_loss: 2.1233 - val_accuracy: 0.4081\n",
      "Epoch 10/20\n",
      "168/168 [==============================] - 524s 3s/step - loss: 0.7594 - accuracy: 0.7041 - val_loss: 2.2002 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "168/168 [==============================] - 521s 3s/step - loss: 0.7238 - accuracy: 0.7244 - val_loss: 2.2377 - val_accuracy: 0.5217\n",
      "Epoch 12/20\n",
      "168/168 [==============================] - 523s 3s/step - loss: 0.6631 - accuracy: 0.7467 - val_loss: 2.2880 - val_accuracy: 0.4679\n",
      "Epoch 13/20\n",
      "168/168 [==============================] - 518s 3s/step - loss: 0.6931 - accuracy: 0.7335 - val_loss: 2.3406 - val_accuracy: 0.4955\n",
      "Epoch 14/20\n",
      "168/168 [==============================] - 465s 3s/step - loss: 0.6237 - accuracy: 0.7607 - val_loss: 2.3790 - val_accuracy: 0.4290\n",
      "Epoch 15/20\n",
      "168/168 [==============================] - 463s 3s/step - loss: 0.5982 - accuracy: 0.7724 - val_loss: 2.3645 - val_accuracy: 0.4380\n",
      "Epoch 16/20\n",
      "168/168 [==============================] - 462s 3s/step - loss: 0.5609 - accuracy: 0.7854 - val_loss: 2.4100 - val_accuracy: 0.4335\n",
      "Epoch 17/20\n",
      "168/168 [==============================] - 462s 3s/step - loss: 0.5146 - accuracy: 0.8010 - val_loss: 2.4372 - val_accuracy: 0.4499\n",
      "Epoch 18/20\n",
      "168/168 [==============================] - 459s 3s/step - loss: 0.4967 - accuracy: 0.8087 - val_loss: 2.4846 - val_accuracy: 0.4649\n",
      "Epoch 19/20\n",
      "168/168 [==============================] - 460s 3s/step - loss: 0.4803 - accuracy: 0.8206 - val_loss: 2.4904 - val_accuracy: 0.4679\n",
      "Epoch 20/20\n",
      "168/168 [==============================] - 461s 3s/step - loss: 0.4321 - accuracy: 0.8331 - val_loss: 2.7545 - val_accuracy: 0.4268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x227734c8710>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same attempt, but with VGG19\n",
    "import keras\n",
    "from tensorflow.keras.applications import VGG19\n",
    "base_model = VGG16(weights='imagenet',\n",
    "                   input_shape=(224, 224, 3),\n",
    "                   include_top=False)\n",
    "base_model.trainable = False\n",
    "from tensorflow.keras import models, layers\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer = layers.Dense(80, activation='relu')\n",
    "dense_layer2 = layers.Dense(40, activation='relu')\n",
    "prediction_layer = layers.Dense(8, activation='softmax')\n",
    "\n",
    "xfer_vgg19_model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer,\n",
    "    dense_layer2,\n",
    "    prediction_layer\n",
    "])\n",
    "xfer_vgg19_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "xfer_vgg19_model.fit(train_it, epochs=20, validation_data=valid_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 90s 2s/step\n",
      "0.414050822122571\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy score\n",
    "\n",
    "predictions = xfer_vgg19_model.predict(valid_it)\n",
    "score = accuracy_score(y_true=valid_it.classes, y_pred=predictions.argmax(axis=-1))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.09      0.12        55\n",
      "           1       0.47      0.57      0.52        60\n",
      "           2       0.35      0.50      0.42       371\n",
      "           3       0.15      0.27      0.19        62\n",
      "           4       0.07      0.08      0.07        38\n",
      "           5       0.54      0.64      0.59        50\n",
      "           6       0.63      0.46      0.53       575\n",
      "           7       0.18      0.10      0.13       127\n",
      "\n",
      "    accuracy                           0.41      1338\n",
      "   macro avg       0.32      0.34      0.32      1338\n",
      "weighted avg       0.44      0.41      0.42      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the classification report with precision, recall, and f1-score\n",
    "# and number of examples for each category\n",
    "\n",
    "print(metrics.classification_report(valid_it.classes, predictions.argmax(axis=-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function to show an image\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)\n",
    "\n",
    "show_image('C:\\\\Users\\\\elanw\\\\OneDrive\\\\Pictures\\\\eye_square.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load image from path and preprocess it\n",
    "\n",
    "\n",
    "def load_and_process_image(image_path):\n",
    "    img = image_utils.load_img(image_path, target_size=(224,224))\n",
    "    img = image_utils.img_to_array(img)\n",
    "    img = img.reshape(1,224,224,3)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
