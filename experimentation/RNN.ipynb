{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Intro to AI Group 3 Final Project - Using CV to Predict Ocular Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_dir = \"C:\\\\Users\\\\elanw\\\\OneDrive\\\\Documents\\\\IntroToAI\\\\ocular_dataset\\\\train\"\n",
    "valid_base_dir = \"C:\\\\Users\\\\elanw\\\\OneDrive\\\\Documents\\\\IntroToAI\\\\ocular_dataset\\\\valid\"\n",
    "test_base_dir = \"C:\\\\Users\\\\elanw\\\\OneDrive\\\\Documents\\\\IntroToAI\\\\ocular_dataset\\\\test\"\n",
    "image_dir = \"C:\\\\Users\\\\elanw\\\\OneDrive\\\\Documents\\\\IntroToAI\\\\ocular_dataset\\\\preprocessed_images\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow v2.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8 # total classes (0-9 digits).\n",
    "num_features = 50176 # data features (img shape: 28*28).\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "batch_size = 32\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "# MNIST image shape is 28*28px, we will then handle 28 sequences of 28 timesteps for every sample.\n",
    "num_input = 224 # number of sequences.\n",
    "timesteps = 224  # timesteps.\n",
    "num_units = 32 # number of neurons for the LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 images belonging to 8 classes.\n",
      "Found 1275 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up Image Data Generators for train, valid & test\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=False, vertical_flip=False, validation_split=0.2)\n",
    "train_it = train_datagen.flow_from_directory(train_base_dir, target_size=(224, 224), color_mode='grayscale', class_mode='categorical', batch_size=5117, subset='training', shuffle=False)\n",
    "valid_it = train_datagen.flow_from_directory(train_base_dir, target_size=(224, 224), color_mode='grayscale', class_mode='categorical', batch_size=1275, subset='validation', shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(train_it)\n",
    "x_valid, y_valid = next(valid_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 224, 224, 1)\n",
      "(5117, 224, 224)\n",
      "0.0\n",
      "0.85882354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "x_train_reshape, x_valid_reshape = X_train.reshape([-1, 224, 224]), x_valid.reshape([-1, num_features])\n",
    "x_train_reshape, x_valid_reshape = x_train_reshape/255, x_valid_reshape/255\n",
    "print(x_train_reshape.shape)\n",
    "print(x_train_reshape[4].min())\n",
    "print(x_train_reshape[4].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "y_train = train_it.classes\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elanw\\OneDrive\\Documents\\IntroToAI\\Final_Project\\CV-Prediction-of-Ocular-Disease\\RNN.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elanw/OneDrive/Documents/IntroToAI/Final_Project/CV-Prediction-of-Ocular-Disease/RNN.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train \u001b[39m=\u001b[39m train_it\u001b[39m.\u001b[39mdata\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elanw/OneDrive/Documents/IntroToAI/Final_Project/CV-Prediction-of-Ocular-Disease/RNN.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Prepare MNIST data.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elanw/OneDrive/Documents/IntroToAI/Final_Project/CV-Prediction-of-Ocular-Disease/RNN.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m mnist\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "x_train = train_it.data\n",
    "\n",
    "# Prepare MNIST data.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train_reshape, y_train), (x_valid_, y_test) = mnist.load_data()\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Flatten images to 1-D vector of 784 features (28*28).\n",
    "x_train, x_test = x_train.reshape([-1, 28, 28]), x_test.reshape([-1, num_features])\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train_reshape, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM Model.\n",
    "class LSTM(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        # RNN (LSTM) hidden layer.\n",
    "        self.lstm_layer = layers.LSTM(units=num_units)\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        # LSTM layer.\n",
    "        x = self.lstm_layer(x)\n",
    "        # Output layer (num_classes).\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build LSTM model.\n",
    "lstm_net = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Adam optimizer.\n",
    "optimizer = tf.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = lstm_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = lstm_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update weights following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100, loss: 1.490094, accuracy: 0.500000\n",
      "step: 200, loss: 1.590143, accuracy: 0.437500\n",
      "step: 300, loss: 1.441734, accuracy: 0.343750\n",
      "step: 400, loss: 1.478670, accuracy: 0.468750\n",
      "step: 500, loss: 1.702457, accuracy: 0.343750\n",
      "step: 600, loss: 1.780766, accuracy: 0.187500\n",
      "step: 700, loss: 1.537272, accuracy: 0.468750\n",
      "step: 800, loss: 1.637721, accuracy: 0.406250\n",
      "step: 900, loss: 1.559122, accuracy: 0.375000\n",
      "step: 1000, loss: 1.462396, accuracy: 0.562500\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = lstm_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once if you have not already done so, not multiple times.\n",
    "# This will take take the csv and the folder of images, and make copies\n",
    "# sorted into train, valid, and test folders, and then category\n",
    "# subfolders within those folders.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "categs = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "\n",
    "if not os.path.exists(train_base_dir):\n",
    "        os.mkdir(train_base_dir)\n",
    "if not os.path.exists(valid_base_dir):\n",
    "        os.mkdir(valid_base_dir)\n",
    "if not os.path.exists(test_base_dir):\n",
    "        os.mkdir(test_base_dir)\n",
    "\n",
    "for categ in categs:\n",
    "    if not os.path.exists(train_base_dir + \"\\\\\" + categ):\n",
    "        os.mkdir(train_base_dir + \"\\\\\" + categ)\n",
    "for categ in categs:\n",
    "    if not os.path.exists(valid_base_dir + \"\\\\\" + categ):\n",
    "        os.mkdir(valid_base_dir + \"\\\\\" + categ)\n",
    "for categ in categs:\n",
    "    if not os.path.exists(test_base_dir + \"\\\\\" + categ):\n",
    "        os.mkdir(test_base_dir + \"\\\\\" + categ)\n",
    "\n",
    "\n",
    "for index, row in ocular_data.iterrows():\n",
    "    l_file = str(row['ID']) + \"_left.jpg\"\n",
    "    r_file = str(row['ID'])+ \"_right.jpg\"\n",
    "    if row['N'] == 1:\n",
    "        dest = train_base_dir + \"\\\\N\\\\\"\n",
    "    elif row['D'] == 1:\n",
    "        dest = train_base_dir + \"\\\\D\\\\\"\n",
    "    elif row['G'] == 1:\n",
    "        dest = train_base_dir + \"\\\\G\\\\\"\n",
    "    elif row['C'] == 1:\n",
    "        dest = train_base_dir + \"\\\\C\\\\\"\n",
    "    elif row['A'] == 1:\n",
    "        dest = train_base_dir + \"\\\\A\\\\\"\n",
    "    elif row['H'] == 1:\n",
    "        dest = train_base_dir + \"\\\\H\\\\\"\n",
    "    elif row['M'] == 1:\n",
    "        dest = train_base_dir + \"\\\\M\\\\\"\n",
    "    elif row['O'] == 1:\n",
    "        dest = train_base_dir + \"\\\\O\\\\\"\n",
    "    if os.path.exists(image_dir + l_file):\n",
    "        shutil.copy(image_dir + l_file, dest + l_file)\n",
    "    if os.path.exists(image_dir + r_file):\n",
    "        shutil.copy(image_dir + r_file, dest + r_file)\n",
    "\n",
    "for categ in categs:\n",
    "    numb_files = len(os.listdir(train_base_dir + \"\\\\\" + categ))\n",
    "    fifteen_percent = numb_files * .15\n",
    "    idx = -1\n",
    "    for filename in os.listdir(train_base_dir + \"\\\\\" + categ):\n",
    "        idx = idx + 1\n",
    "        if idx < fifteen_percent:\n",
    "            shutil.move(train_base_dir + \"\\\\\" + categ + \"\\\\\" + filename, valid_base_dir + \"\\\\\" + categ + \"\\\\\" + filename)\n",
    "        elif idx < fifteen_percent * 2:\n",
    "            shutil.move(train_base_dir + \"\\\\\" + categ + \"\\\\\" + filename, test_base_dir + \"\\\\\" + categ + \"\\\\\" + filename)\n",
    "        else:\n",
    "            break\n",
    "     \n",
    "\n",
    "# create directory for each category\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This duplicates training data by creating a horizontally flipped version of each.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "categs = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "for category in categs:\n",
    "    for file in os.listdir(train_base_dir + \"\\\\\" + category):\n",
    "        img = cv2.imread(train_base_dir + \"\\\\\" + category + \"\\\\\" + file)\n",
    "        flipped_img = cv2.flip(img, 1)\n",
    "        cv2.imwrite(train_base_dir + \"\\\\\" + category + \"\\\\\" + file[:-4] + \"_flipped.jpg\", flipped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma = .01, C = 100)\n",
    "# train using clf\n",
    "clf.fit(train_it, valid_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam optimizer, grayscale, all images \"facing\" same way, # normalized by dividing by 255\n",
    "cnn_model.fit(train_it, epochs=11, validation_data=valid_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam optimizer, colored, all images \"facing\" same way\n",
    "cnn_model.fit(train_it, epochs=6, validation_data=valid_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# highest yet is 45% validation accuracy\n",
    "cnn_model.fit(train_it, epochs=7, validation_data=valid_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the accuracy score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = xfer_vgg19_model.predict(test_it)\n",
    "score = accuracy_score(y_true=test_it.classes, y_pred=predictions.argmax(axis=-1))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the classification report with precision, recall, and f1-score\n",
    "# and number of examples for each category\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(test_it.classes, predictions.argmax(axis=-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function to show an image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)\n",
    "\n",
    "show_image('C:\\\\Users\\\\elanw\\\\OneDrive\\\\Pictures\\\\eye_square.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load image from path and preprocess it\n",
    "\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def load_and_process_image(image_path):\n",
    "    img = image_utils.load_img(image_path, target_size=(224,224))\n",
    "    img = image_utils.img_to_array(img)\n",
    "    img = img.reshape(1,224,224,3)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
